{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "## CRISP-DM: Modeling\n",
    "**Autor:** Wanderson Marques - wdsmarques@gmail.com\n",
    "\n",
    "Esse Jupyter Notebook contém a escolha do **modelo e parâmetros** para conjunto de dados Titanic. A modelagem refere-se à quarta fase da metodologia CRISP-DM. \n",
    "\n",
    "<img src=\"imgs/modeling.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse momento, o dataset já está pré-processado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.802787</td>\n",
       "      <td>-9.864448e-01</td>\n",
       "      <td>-0.471492</td>\n",
       "      <td>-0.47646</td>\n",
       "      <td>-0.376645</td>\n",
       "      <td>1.367833</td>\n",
       "      <td>2.136001</td>\n",
       "      <td>-0.301775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.405272</td>\n",
       "      <td>-1.570346e-01</td>\n",
       "      <td>0.491588</td>\n",
       "      <td>-0.47646</td>\n",
       "      <td>-0.151489</td>\n",
       "      <td>1.367833</td>\n",
       "      <td>2.136001</td>\n",
       "      <td>-0.301775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.802787</td>\n",
       "      <td>2.678779e-16</td>\n",
       "      <td>-0.471492</td>\n",
       "      <td>-0.47646</td>\n",
       "      <td>-0.531501</td>\n",
       "      <td>-0.731083</td>\n",
       "      <td>-0.468165</td>\n",
       "      <td>-0.301775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.802787</td>\n",
       "      <td>-7.602420e-01</td>\n",
       "      <td>-0.471492</td>\n",
       "      <td>-0.47646</td>\n",
       "      <td>-0.485487</td>\n",
       "      <td>-0.731083</td>\n",
       "      <td>-0.468165</td>\n",
       "      <td>-0.301775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.405272</td>\n",
       "      <td>2.678779e-16</td>\n",
       "      <td>-0.471492</td>\n",
       "      <td>-0.47646</td>\n",
       "      <td>-0.717819</td>\n",
       "      <td>-0.731083</td>\n",
       "      <td>-0.468165</td>\n",
       "      <td>-0.301775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass           Age     SibSp    Parch      Fare  Sex_female  \\\n",
       "0  0.802787 -9.864448e-01 -0.471492 -0.47646 -0.376645    1.367833   \n",
       "1 -0.405272 -1.570346e-01  0.491588 -0.47646 -0.151489    1.367833   \n",
       "2  0.802787  2.678779e-16 -0.471492 -0.47646 -0.531501   -0.731083   \n",
       "3  0.802787 -7.602420e-01 -0.471492 -0.47646 -0.485487   -0.731083   \n",
       "4 -0.405272  2.678779e-16 -0.471492 -0.47646 -0.717819   -0.731083   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Survived  \n",
       "0    2.136001   -0.301775         0  \n",
       "1    2.136001   -0.301775         1  \n",
       "2   -0.468165   -0.301775         0  \n",
       "3   -0.468165   -0.301775         0  \n",
       "4   -0.468165   -0.301775         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/train-preprocessado.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.drop(['Survived'], axis=1)\n",
    "y = dataset['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testar modelos e parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realização de experimentos para encontar o modelo preditivo e parâmetros que melhor explicam a relação entre as variáveis preditoras e a predita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dicionário com classificadores candidatos\n",
    "modelos = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Neural Network': MLPClassifier(),\n",
    "    'Naives Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Vetor de dicionários dos parâmetros possíveis para cada classificador. Estes serão combinados pelo GridSearchCV\n",
    "parametros = [\n",
    "    {'n_neighbors': [3, 5, 7], 'metric': ['euclidean', 'minkowski', 'manhattan']},\n",
    "    {'n_estimators': [50, 100, 200], 'min_samples_split': [2, 5, 10]},\n",
    "    {'hidden_layer_sizes': [25, 50, 100, (25,25), (50,50), (100, 100)], 'activation': ['logistic', 'relu']},\n",
    "    {}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando  KNN\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1918s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0480s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando  Random Forest\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   22.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando  Neural Network\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   45.2s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando  Naives Bayes\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   14.8s remaining:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   14.8s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   14.8s finished\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "i = 0\n",
    "for nome, modelo in modelos.items():\n",
    "    print(\"Treinando \", nome)\n",
    "    \n",
    "    # Combinar os parâmetros de cada modelo com cross-validation (10 folds)\n",
    "    gs = GridSearchCV(modelo, parametros[i], scoring='accuracy', n_jobs=-1, verbose=10, cv=10)\n",
    "    gs.fit(X, y)\n",
    "    results.append([nome, gs.best_params_, gs.best_score_])\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "resultados = pd.DataFrame(results, columns=['Modelo', 'Melhor Parâmetros', 'Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar resultados (Utilizando Acurácia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Melhor Parâmetros</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_samples_split': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.873737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.845960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 3}</td>\n",
       "      <td>0.839646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naives Bayes</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.808081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Modelo                                  Melhor Parâmetros     Score\n",
       "1   Random Forest     {'min_samples_split': 10, 'n_estimators': 200}  0.873737\n",
       "2  Neural Network  {'activation': 'relu', 'hidden_layer_sizes': (...  0.845960\n",
       "0             KNN          {'metric': 'manhattan', 'n_neighbors': 3}  0.839646\n",
       "3    Naives Bayes                                                 {}  0.808081"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados.sort_values('Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinar melhor modelo com melhores parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(min_samples_split=10, n_estimators=200)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar desempenho para o conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       396\n",
      "          1       0.96      0.89      0.93       396\n",
      "\n",
      "avg / total       0.93      0.93      0.93       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar modelo preditivo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, filename='models/model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
